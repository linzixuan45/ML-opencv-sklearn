{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 4, 9], dtype=int32)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''测试'''\n",
    "import numpy as np\n",
    "\n",
    "mm = np.array([1,2,3])\n",
    "pow(mm,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harris opencv 的对应代码\n",
    "cv2.cornerHarris(src, blockSize, ksize, k[, dst[, borderType]])\n",
    "   参数类型\n",
    "   src - 输入灰度图像，float32类型\n",
    "    blockSize - 用于角点检测的邻域大小，就是上面提到的窗口的尺寸\n",
    "    ksize - 用于计算梯度图的Sobel算子的尺寸\n",
    "    k - 用于计算角点响应函数的参数k，取值范围常在0.04~0.06之间\n",
    "\n",
    "注：Sobel算子是滤波算子的形式,利用快速卷积函数， 简单有效，因此应用广泛\n",
    "    优点：方法简单、处理速度快,并且所得的边缘光滑\n",
    "    缺点：Sobel算子并没有将图像的主体与背景严格地区分开来，换言之就是Sobel算子没有基于图像灰度进行处理\n",
    "    原理：\n",
    "    sobel算子的horizon垂直检测Sob_x：\n",
    "        [[-1,0,1],\n",
    "        [-2,0,2],\n",
    "        [-1,0,1]]\n",
    "    sobel算子的vertical水平检测 Sob_y：\n",
    "        [[1,2,1],\n",
    "        [0,0,0],\n",
    "        [-1,-2,-1]]\n",
    "    矩阵公式：\n",
    "            Gx = Sob_x *img.data  Gy = Sob_y * img.data\n",
    "            G的运算采用L2 范数,节约时间可用L1范数\n",
    "            L2：G = np.sqrt(pow(Gx,2)+pow(Gy,2)\n",
    "            L1：G = |Gx|+|Gy|\n",
    "            得到梯度值,若G大于阈值threshold,则说明有角点\n",
    "            再由 theta = 1/tan(Gy/Gx)得到梯度的方向\n",
    "            若theta 角度为0 代表图像有纵向边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''sobel算子的实现'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "'''Sober算子,初始化'''\n",
    "sob_x ,sob_y= [[-1,0,1],[-2,0,2],[-1,0,1]], \\\n",
    "              [[1,2,1],[0,0,0],[-1,-2,-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) c:\\miniconda3\\conda-bld\\opencv-suite_1534379934306\\work\\modules\\imgproc\\src\\color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'cv::CvtHelper<struct cv::Set<3,4,-1>,struct cv::Set<1,-1,-1>,struct cv::Set<0,2,5>,2>::CvtHelper'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-33-d5def099eb6c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mimg1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mr'D:\\_py项目文件夹\\ML-opencv-sklearn\\Machine-Learning-for-OpenCV-Second-Edition\\figures\\image1.jpeg'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#读取通道为BGR\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mimg1_gray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCOLOR_BGR2GRAY\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#BGR通道转为Gray,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;31m# 类型type(img1_gray)  numpy.ndarray,shape (390, 700)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(3.4.2) c:\\miniconda3\\conda-bld\\opencv-suite_1534379934306\\work\\modules\\imgproc\\src\\color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'cv::CvtHelper<struct cv::Set<3,4,-1>,struct cv::Set<1,-1,-1>,struct cv::Set<0,2,5>,2>::CvtHelper'\n"
     ]
    }
   ],
   "source": [
    "'''图片读取并灰度化'''\n",
    "img1 = cv2.imread(r'D:\\_py项目文件夹\\ML-opencv-sklearn\\Machine-Learning-for-OpenCV-Second-Edition\\figures\\image1.jpeg') #读取通道为BGR\n",
    "print(type(img1))\n",
    "img1_gray = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY) #BGR通道转为Gray,\n",
    "# 类型type(img1_gray)  numpy.ndarray,shape (390, 700)\n",
    "\n",
    "plt.imshow(img1_gray,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''这里舍弃最外围的一圈像素点 实际sobel算子卷积了 388x698图片'''\n",
    "\n",
    "# 切片操作，取第一个需要卷积的矩阵，其核心位置为【1，1】\n",
    "d10 = img1_gray[0:10,0:10]\n",
    "d1 = img1_gray[0:3,0:3]\n",
    "sob_d1 = np.abs(np.sum(sob_x*d1)) +np.abs(np.sum(sob_y * d1))\n",
    "d10,d1,f'最开始的卷积之后的值 = {sob_d1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''定义一个卷积函数'''\n",
    "def convolution_ndarray(kernal, data_gray):\n",
    "    n, m = data_gray.shape  # (390, 700)\n",
    "    img_new = np.zeros((n-2, m-2))\n",
    "    for i in range(n-2 ):  # [0,387)\n",
    "        temp_row = np.zeros(m-2)  # 700\n",
    "        for j in range(m -2):  # [ 0,697)\n",
    "            temp = data_gray[i:i + 3, j:j + 3]\n",
    "            temp_row[j] = np.sum(np.multiply(kernal, temp))\n",
    "        img_new[i] = temp_row\n",
    "    return img_new\n",
    "\n",
    "\n",
    "\n",
    "Gx = convolution_ndarray(sob_x,img1_gray)\n",
    "\n",
    "Gy = convolution_ndarray(sob_y,img1_gray)\n",
    "# L1范数\n",
    "G_L1 = np.absolute(Gx) +np.absolute(Gy)\n",
    "# L2范数\n",
    "G_L2 = np.sqrt(pow(Gx,2)+pow(Gy,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 255矩阵\n",
    "\n",
    "ones = np.ones(G_L1.shape)*255 #ones.shape (387, 697)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img1_gray, cmap='gray')\n",
    "plt.title('Sober + row_data ')\n",
    "\n",
    "Color_Reversal_1 = ones -G_L1 #颜色反转\n",
    "plt.subplot(132)\n",
    "plt.imshow(Color_Reversal_1,cmap='gray')\n",
    "plt.title(' Sober + G_L1')\n",
    "\n",
    "Color_Reversal_2 = ones-G_L2    #颜色反转\n",
    "plt.subplot(133)\n",
    "plt.imshow(G_L2,cmap='gray')\n",
    "plt.title(' Sober +G_L2 ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用opencv 封装的Harris 角点检测方法检测角点\n",
    "图像的角点检测\n",
    "检测图像中的角点（几条边相交的位置)\n",
    "1.Harris角点检测 思想：边缘是在各个方向上都具有高密度变化的区域 算法基本思想是使用一个固定窗口在图像上进行任意方向上的滑动，比较滑动前与滑动后两种情况，窗口中的像素灰度变化程度，如果存在任意方向上的滑动，都有着较大灰度变化，那么我们可以认为该窗口中存在角点。\n",
    "角点的特征：\n",
    "    >轮廓之间的交点；\n",
    "    >对于同一场景，即使视角发生变化，通常具备稳定性质的特征；\n",
    "    >该点附近区域的像素点无论在梯度方向上还是其梯度幅值上有着较大变化;\n",
    "    >就是一阶导数(即灰度图的梯度)中的局部最大所对应的像素点就是角点.\n",
    "harris 角点检测的步骤\n",
    "    1.当窗口（小的图像片段）同时向 x 和 y 两个方向移动时，计算窗口内部的像素值变化量 d f(x,y) ;\n",
    "    2.对于每个窗口，都计算其对应的一个角点激活函数 G;\n",
    "    3.然后对该函数进行阈值处理，如果 G > threshold，表示该窗口对应一个角点特征.\n",
    "\n",
    "2.Shi-Tomasi角点检测\n",
    "    Harris角点检测的改进版\n",
    "    Shi-Tomasi 发现，角点的稳定性其实和矩阵 M 的较小特征值有关\n",
    "\n",
    "\n",
    "OpenCV 中的 Harris 角点检测\n",
    "Open 中的函数 cv2.cornerHarris() 可以用来进行角点检测。参数如下:\n",
    "　　• img - 数据类型为 float32 的输入图像。\n",
    "　　• blockSize - 角点检测中要考虑的领域大小。\n",
    "　　• ksize - Sobel 求导中使用的窗口大小\n",
    "　　• k - Harris 角点检测方程中的自由参数,取值参数为 [0,04,0.06]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''角点检测的magic_cube原始图片'''\n",
    "magic_cube= cv2.imread('figures/magic_cube.jpg')  #cv2读取是BGR格式\\\n",
    "cube = plt.imread('figures/magic_cube.jpg')\n",
    "b,g,r = cv2.split(magic_cube)\n",
    "magic_cube_rgb = cv2.merge((r,g,b))\n",
    "# magic_cube = cv2.cvtColor(magic_cube,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(cube)\n",
    "plt.title(\"magic_cube_rgb\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "magic_cube_gray = cv2.cvtColor(magic_cube,cv2.COLOR_BGR2GRAY)\n",
    "corners_Harris = cv2.cornerHarris(magic_cube_gray,3,3,0.06) #shape (500, 500)\n",
    "#Sobel运算x，y\n",
    "cube_G_x = convolution_ndarray(sob_x,magic_cube_gray)\n",
    "cube_G_y = convolution_ndarray(sob_y, magic_cube_gray)\n",
    "cube_G_L1 =np.absolute(cube_G_x) +np.absolute(cube_G_y)\n",
    "\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.subplot(131)\n",
    "plt.imshow(magic_cube_gray,cmap ='gray')\n",
    "plt.subplot(132)\n",
    "plt.imshow(corners_Harris,cmap='gray')\n",
    "plt.subplot(133)\n",
    "plt.imshow(cube_G_L1,cmap='gray')\n",
    "plt.show()\n",
    "'''如下图所示，直接显示的检测效果并不理想，但sobel算子运算得到的边缘图十分明显\n",
    "cube的上面灰度值与255较为接近，偏差不明显，之后使用threshold进行角点检测'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''对该函数进行阈值处理，如果 G > threshold，表示该窗口对应一个角点特征.'''\n",
    "threshold= 0.01*corners_Harris.max()\n",
    "flag = corners_Harris > threshold\n",
    "\n",
    "\n",
    "'''方法1，由np.where 直接找到 符合条件的array 下标'''\n",
    "# where(condition, [x, y])\n",
    "# x,y = np.where(flag) #返回tuple 返回了一个基于原本数据的地址索引 type() -> 2\n",
    "x,y = np.where(flag)\n",
    "\n",
    "corners_data1 = []\n",
    "for i,j in zip(x,y):\n",
    "    corners_data1.append(corners_Harris[i][j])\n",
    "'''方法2，由 统计学习的数学运算方法传入一个由True，false组成的flag，\n",
    "直接得到一个符合条件的一维数据'''\n",
    "corners_data2 = corners_Harris[flag]\n",
    "\n",
    "\n",
    "'''测试data_index 所指向的数据是否和corners_data所记录的符合的数据一致'''\n",
    "corners_data1 == corners_data2\n",
    "#数据比对均为True，说明由方法1和方法2获得的数据一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''对于方法2的解释说明'''\n",
    "a = np.array([[1,2,3],[1,2,3]])\n",
    "flag1 = np.array([[True,True,True],[False,True,False]])\n",
    "b = a[flag1] #这种方法只是返回合格的数据，但并没有原始数据所在的下标，且形状为1维，适合label标签的选取分类\n",
    "\n",
    "'''plot 绘制角点'''\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.subplot(121)\n",
    "plt.scatter(y,x,c = 'red')\n",
    "plt.imshow(magic_cube_gray,cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.scatter(y,x,c = 'red')\n",
    "plt.imshow(cube_G_L1,cmap='gray')\n",
    "plt.show()\n",
    "plt.savefig('figures/cube_Harris.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "如上图所示,角点位置坐标全部标注为红色,数据在X,Y中保存对应的位置下标,实测所知,得到的数据x\n",
    ",y转换后可以正常画图使用 即x,y = y,x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}